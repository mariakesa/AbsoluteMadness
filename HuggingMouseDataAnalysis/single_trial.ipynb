{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(900, 184832)\n",
      "Error processing container 511510736, session three_session_A: name 'm' is not defined\n",
      "(900, 184832)\n",
      "Error processing container 511510736, session three_session_B: name 'm' is not defined\n",
      "(900, 184832)\n",
      "Error processing container 511510736, session three_session_C: name 'm' is not defined\n",
      "Error processing container 511510736, session three_session_C2: 'three_session_C2'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 253\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m    252\u001b[0m start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 253\u001b[0m \u001b[43mmake_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m end\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100 pulls time: \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m-\u001b[39mstart)\n",
      "Cell \u001b[0;32mIn[5], line 235\u001b[0m, in \u001b[0;36mmake_df\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     cnt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 235\u001b[0m results,regr_dims\u001b[38;5;241m=\u001b[39mcompile_dfs(sess_dct)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m#regr_dims=compile_dfs(regr_vec_dct)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_test_regression.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "#from make_embeddings import StimPrep\n",
    "import os\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import null_space\n",
    "import numpy as np\n",
    "import json, codecs\n",
    "\n",
    "cache_path = \"/media/maria/DATA/AllenData\"\n",
    "save_path = \"/media/maria/DATA/BrainObservatoryProcessedData\"\n",
    "\n",
    "stimulus_session_dict= {\n",
    "    'three_session_A': ['natural_movie_one', 'natural_movie_three'],\n",
    "    'three_session_B': ['natural_movie_one'],\n",
    "    'three_session_C': ['natural_movie_one', 'natural_movie_two'],\n",
    "    'three_session_C2': ['natural_movie_one', 'natural_movie_two']\n",
    "}\n",
    "\n",
    "\n",
    "def ridge_regression(dat_dct):\n",
    "\n",
    "    y_train, y_test, X_train, X_test= dat_dct['y_train'], dat_dct['y_test'], dat_dct['X_train'], dat_dct['X_test']\n",
    "\n",
    "    regr=Ridge(10)\n",
    "\n",
    "    # Fit the model with scaled training features and target variable\n",
    "    regr.fit(X_train, y_train.T)\n",
    "\n",
    "    # Make predictions on scaled test features\n",
    "    predictions = regr.predict(X_test)\n",
    "\n",
    "    scores=[]\n",
    "    for i in range(0,y_test.shape[0]):\n",
    "        scores.append(r2_score(y_test.T[:,i], predictions[:,i]))\n",
    "    return scores, regr.coef_\n",
    "\n",
    "#rng = np.random.default_rng(77)\n",
    "\n",
    "class ProcessMovieRecordings:\n",
    "    def __init__(self):\n",
    "        self.boc = BrainObservatoryCache(manifest_file=str(\n",
    "                Path(cache_path) / 'brain_observatory_manifest.json'))\n",
    "        \n",
    "        self.eid_dict = self.make_container_dict()\n",
    "        #self.dataset = boc.get_ophys_experiment_data(eid)\n",
    "        #self.cell_ids = self.dataset.get_cell_specimen_ids()\n",
    "        #self.stimulus = stimulus\n",
    "        self.random_state_dct=self.generate_random_state()\n",
    "        #self.embeddings = self.get_embeddings()\n",
    "\n",
    "    def generate_random_state(self):\n",
    "        np.random.seed(7)\n",
    "\n",
    "        # Function to generate a random integer\n",
    "        def generate_random_integer():\n",
    "            return np.random.randint(1, 101)  # Generates a random integer between 1 and 100 (inclusive)\n",
    "\n",
    "        # Create the main dictionary\n",
    "        random_state_dct = {}\n",
    "\n",
    "        # Populate the dictionary using stimulus_session_dict\n",
    "        for session, stimuli_list in stimulus_session_dict.items():\n",
    "            session_dict = {}\n",
    "            for stimulus in stimuli_list:\n",
    "                nested_dict = {trial: generate_random_integer() for trial in range(10)}\n",
    "                session_dict[stimulus] = nested_dict\n",
    "            random_state_dct[session] = session_dict\n",
    "        return random_state_dct\n",
    "\n",
    "    def make_container_dict(self):\n",
    "        '''\n",
    "        Parses which experimental id's (values)\n",
    "        correspond to which experiment containers (keys).\n",
    "        '''\n",
    "        experiment_container = self.boc.get_experiment_containers()\n",
    "        container_ids=[dct['id'] for dct in experiment_container]\n",
    "        eids=self.boc.get_ophys_experiments(experiment_container_ids=container_ids)\n",
    "        df=pd.DataFrame(eids)\n",
    "        reduced_df=df[['id', 'experiment_container_id', 'session_type']]\n",
    "        grouped_df = df.groupby(['experiment_container_id', 'session_type'])['id'].agg(list).reset_index()\n",
    "        eid_dict = {}\n",
    "        for row in grouped_df.itertuples(index=False):\n",
    "            container_id, session_type, ids = row\n",
    "            if container_id not in eid_dict:\n",
    "                eid_dict[container_id] = {}\n",
    "            eid_dict[container_id][session_type] = ids[0]\n",
    "        return eid_dict\n",
    "\n",
    "\n",
    "    def make_data_dct(self, data_dct, dataset, stimulus):\n",
    "        data_dct['movie_stim_table_'+stimulus] = dataset.get_stimulus_table(stimulus)\n",
    "        return data_dct\n",
    "    \n",
    "\n",
    "    def process_single_trial(self, movie_stim_table, dff_traces, trial, embedding, random_state):\n",
    "        stimuli = movie_stim_table.loc[movie_stim_table['repeat'] == trial]\n",
    "        X_train, X_test, y_train_inds, y_test_inds = train_test_split(embedding,stimuli['start'].values, test_size=0.2, random_state=random_state)\n",
    "        y_train= dff_traces[:,y_train_inds]\n",
    "        y_test= dff_traces[:,y_test_inds]\n",
    "        return {'y_train': y_train, 'y_test': y_test, 'X_train': X_train, 'X_test': X_test}\n",
    "        \n",
    "\n",
    "\n",
    "    def make_regression_data(self, container_id, session):\n",
    "        session_eid  = self.eid_dict[container_id][session]\n",
    "        dataset = self.boc.get_ophys_experiment_data(session_eid)\n",
    "        cell_ids = dataset.get_cell_specimen_ids()\n",
    "        dff_traces = dataset.get_dff_traces()[1]\n",
    "        #movie_one = dataset.get_stimulus_template('natural_movie_one')\n",
    "        session_stimuli = stimulus_session_dict[session]\n",
    "        session_dct = pd.DataFrame()\n",
    "        regression_vec_dct={}\n",
    "        session_dct['cell_ids'] = cell_ids\n",
    "        #regression_vec_dct['cell_ids'] = cell_ids\n",
    "        #Compile the sessions into the same column to avoind NAN's\n",
    "        #and make the data processing a bit easier\n",
    "        if session=='three_session_C2':\n",
    "            sess='three_session_C'\n",
    "        else:\n",
    "            sess=session\n",
    "        for s in session_stimuli:\n",
    "            movie_stim_table = dataset.get_stimulus_table(s)\n",
    "            #embedding=self.embeddings[stimuli_dct[s][m]]\n",
    "            video=dataset.get_stimulus_template(s)\n",
    "            video=video.reshape(-1,video.shape[1]*video.shape[2])\n",
    "            print(video.shape)\n",
    "            for trial in range(10):\n",
    "                random_state=self.random_state_dct[session][s][trial]\n",
    "                data=self.process_single_trial(movie_stim_table, dff_traces, trial, video, random_state=random_state)\n",
    "                #Code: session-->model-->stimulus-->trial\n",
    "                var_exps, regr_vecs=ridge_regression(data)\n",
    "                session_dct[str(sess)+'_'+'raw_movies'+'_'+str(s)+'_'+str(trial)] = var_exps\n",
    "                regression_vec_dct[str(sess)+'_'+str(m)+'_'+str(s)+'_'+str(trial)]=regr_vecs\n",
    "        return session_dct, regression_vec_dct\n",
    "'''    \n",
    "import time\n",
    "start=time.time()\n",
    "a=ProcessMovieRecordings().make_regression_data(511510736, 'three_session_A')\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "#print(a.keys())\n",
    "'''\n",
    "def pull_data():\n",
    "    output_dir = '/media/maria/DATA/AllenData'\n",
    "    boc = BrainObservatoryCache(manifest_file=str(Path(output_dir) / 'brain_observatory_manifest.json'))\n",
    "    experiment_container = boc.get_experiment_containers()\n",
    "    rng = np.random.default_rng(78)\n",
    "    exp_ids=[dct['id'] for dct in experiment_container]\n",
    "    random_exp_ids = rng.choice(exp_ids, size=100, replace=False)\n",
    "    sessions=['three_session_A', 'three_session_B', 'three_session_C', 'three_session_C2']\n",
    "    processor=ProcessMovieRecordings()\n",
    "    cnt=0\n",
    "    for container_id in random_exp_ids:\n",
    "        print(cnt)\n",
    "        for s in sessions:\n",
    "            try:\n",
    "                processor.make_regression_data(container_id, s)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing container {container_id}, session {s}: {e}\")\n",
    "                continue\n",
    "        cnt+=1\n",
    "\n",
    "def pull_data():\n",
    "    output_dir = '/media/maria/DATA/AllenData'\n",
    "    boc = BrainObservatoryCache(manifest_file=str(Path(output_dir) / 'brain_observatory_manifest.json'))\n",
    "    experiment_container = boc.get_experiment_containers()\n",
    "    rng = np.random.default_rng(78)\n",
    "    exp_ids=[dct['id'] for dct in experiment_container]\n",
    "    random_exp_ids = rng.choice(exp_ids, size=100, replace=False)\n",
    "    sessions=['three_session_A', 'three_session_B', 'three_session_C', 'three_session_C2']\n",
    "    processor=ProcessMovieRecordings()\n",
    "    cnt=0\n",
    "    for container_id in random_exp_ids:\n",
    "        print(cnt)\n",
    "        for s in sessions:\n",
    "            try:\n",
    "                processor.make_regression_data(container_id, s)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing container {container_id}, session {s}: {e}\")\n",
    "                continue\n",
    "        cnt+=1\n",
    "\n",
    "def make_df():\n",
    "    def compile_dfs(sess_dct):\n",
    "        # Initialize an empty DataFrame to store the merged result\n",
    "        merged_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate through each key in sess_dct\n",
    "        for k in sess_dct.keys():\n",
    "            # Retrieve the DataFrame associated with the key\n",
    "            df = sess_dct[k]\n",
    "\n",
    "            # Check if merged_df is empty (first iteration)\n",
    "            if merged_df.empty:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                # Merge the current DataFrame with the existing merged_df based on 'cell_ids' column\n",
    "                merged_df = pd.merge(merged_df, df, on='cell_ids', how='inner')\n",
    "\n",
    "        return merged_df\n",
    "            \n",
    "    output_dir = '/media/maria/DATA/AllenData'\n",
    "    boc = BrainObservatoryCache(manifest_file=str(Path(output_dir) / 'brain_observatory_manifest.json'))\n",
    "    experiment_container = boc.get_experiment_containers()\n",
    "    rng = np.random.default_rng(78)\n",
    "    exp_ids=[dct['id'] for dct in experiment_container]\n",
    "    random_exp_ids = rng.choice(exp_ids, size=100, replace=False)\n",
    "    random_exp_ids = [511510736]\n",
    "    sessions=['three_session_A', 'three_session_B', 'three_session_C', 'three_session_C2']\n",
    "    processor=ProcessMovieRecordings()\n",
    "    sess_dct={}\n",
    "    cnt=0\n",
    "    regr_vec_dct={}\n",
    "    for container_id in random_exp_ids:\n",
    "        print(cnt)\n",
    "        for s in sessions:\n",
    "            try:\n",
    "                df, regr_vec_df =processor.make_regression_data(container_id, s)\n",
    "                sess_dct[s]=df\n",
    "                regr_vec_dct[s]=regr_vec_df\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing container {container_id}, session {s}: {e}\")\n",
    "                #traceback.print_exc()\n",
    "                continue\n",
    "        cnt+=1\n",
    "    results,regr_dims=compile_dfs(sess_dct)\n",
    "    #regr_dims=compile_dfs(regr_vec_dct)\n",
    "    results.to_csv('raw_test_regression.csv')\n",
    "    regr_vec_dct.to_json('regr_dims.json')\n",
    "    #https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable\n",
    "    #json.dump(regr_vec_dct, codecs.open(\"regr_dims_test.json\", 'w', encoding='utf-8'), \n",
    "          #separators=(',', ':'), \n",
    "          #sort_keys=True, \n",
    "          #indent=4)\n",
    "    \n",
    "\n",
    "\n",
    "#start=time.time()\n",
    "#pull_data()\n",
    "#end=time.time()\n",
    "#print('100 pulls time: ', end-start)\n",
    "import time\n",
    "start=time.time()\n",
    "make_df()\n",
    "end=time.time()\n",
    "print('100 pulls time: ', end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
